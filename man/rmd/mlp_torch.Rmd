```{r, child = "setup.Rmd", include = FALSE}
```

`r descr_models("mlp", "torch")`

## Tuning Parameters

```{r torch-param-info, echo = FALSE}
defaults <- 
  tibble::tibble(parsnip = c("hidden_units", "penalty", "dropout", "epochs", "activation"),
                 default = c("5L", "0.001", "0.0", "100L", "'relu'"))

param <-
  mlp() %>% 
  set_engine("torch") %>% 
  tunable() %>% 
  dplyr::select(-source, -component, -component_id, parsnip = name) %>% 
  dplyr::mutate(
    dials = purrr::map(call_info, get_dials),
    label = purrr::map_chr(dials, ~ .x$label),
    type = purrr::map_chr(dials, ~ .x$type)
  ) %>% 
  dplyr::inner_join(defaults, by = "parsnip") %>% 
  mutate(
    item = 
      glue::glue("- `{parsnip}`: {label} (type: {type}, default: {default})\n\n")
  )
```

This model has `r nrow(param)` tuning parameters listed as a main argument:

```{r torch-param-list, echo = FALSE, results = "asis"}
param$item
```

For `penalty`, the amount of regularization is _only_ L2 penalty (i.e., ridge or weight decay). 

There are other parameters that can be set or tuned via [parsnip::set_engine()]:

 - `momentum`:  The amount to adjust the gradient direction/length with the value from a previous iteration. (default: 0.0, `optimizer = 'SGD'` only)
 - `batch_size`:    (default: )
 - `class_weights`: Numeric class weights (classification only).  The value for this argument could be:
    - A named numeric vector (in any order) where the names are the outcome factor levels.
    - An unnamed numeric vector assumed to be in the same order as the outcome factor levels.
    - A single numeric value for the least frequent class in the training data and all other classes receive a weight of one.

Other relevant arguments that are not tuning parameters:

 - `validation`: The proportion of the data randomly assigned to a validation set. (default: 0.1)
 - `optimizer`:  The method used in the optimization procedure. Possible choices are `'LBFGS'` and `'SGD'`. (default: `'LBFGS'`)


## Translation from parsnip to the original package (regression)

```{r torch-reg}
mlp(
  hidden_units = integer(1),
  penalty = double(1),
  dropout = double(1),
  epochs = integer(1),
  activation = character(1)
) %>%  
  set_engine("torch") %>% 
  set_mode("regression") %>% 
  translate()
```

## Translation from parsnip to the original package (classification)

```{r torch-cls}
mlp(
  hidden_units = integer(1),
  penalty = double(1),
  dropout = double(1),
  epochs = integer(1),
  activation = character(1)
) %>% 
  set_engine("torch") %>% 
  set_mode("classification") %>% 
  translate()
```


## Preprocessing requirements

```{r child = "template-makes-dummies.Rmd"}
```

```{r child = "template-same-scale.Rmd"}
```

## References

 - Kuhn, M, and K Johnson. 2013. _Applied Predictive Modeling_. Springer.


