% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lantern_logistic_reg-fit.R
\name{lantern_logistic_reg}
\alias{lantern_logistic_reg}
\alias{lantern_logistic_reg.default}
\alias{lantern_logistic_reg.data.frame}
\alias{lantern_logistic_reg.matrix}
\alias{lantern_logistic_reg.formula}
\alias{lantern_logistic_reg.recipe}
\title{Fit a logistic regression model}
\usage{
lantern_logistic_reg(x, ...)

\method{lantern_logistic_reg}{default}(x, ...)

\method{lantern_logistic_reg}{data.frame}(
  x,
  y,
  epochs = 20L,
  penalty = 0.001,
  validation = 0.1,
  optimizer = "LBFGS",
  learn_rate = 1,
  momentum = 0,
  batch_size = NULL,
  class_weights = NULL,
  stop_iter = 5,
  verbose = FALSE,
  ...
)

\method{lantern_logistic_reg}{matrix}(
  x,
  y,
  epochs = 20L,
  penalty = 0.001,
  validation = 0.1,
  optimizer = "LBFGS",
  learn_rate = 1,
  momentum = 0,
  batch_size = NULL,
  class_weights = NULL,
  stop_iter = 5,
  verbose = FALSE,
  ...
)

\method{lantern_logistic_reg}{formula}(
  formula,
  data,
  epochs = 20L,
  penalty = 0.001,
  validation = 0.1,
  optimizer = "LBFGS",
  learn_rate = 1,
  momentum = 0,
  batch_size = NULL,
  class_weights = NULL,
  stop_iter = 5,
  verbose = FALSE,
  ...
)

\method{lantern_logistic_reg}{recipe}(
  x,
  data,
  epochs = 20L,
  penalty = 0.001,
  validation = 0.1,
  optimizer = "LBFGS",
  learn_rate = 1,
  momentum = 0,
  batch_size = NULL,
  class_weights = NULL,
  stop_iter = 5,
  verbose = FALSE,
  ...
)
}
\arguments{
\item{x}{Depending on the context:
\itemize{
\item A \strong{data frame} of predictors.
\item A \strong{matrix} of predictors.
\item A \strong{recipe} specifying a set of preprocessing steps
created from \code{\link[recipes:recipe]{recipes::recipe()}}.
}

The predictor data should be standardized (e.g. centered or scaled).}

\item{...}{Not currently used, but required for extensibility.}

\item{y}{When \code{x} is a \strong{data frame} or \strong{matrix}, \code{y} is the outcome
specified as:
\itemize{
\item A \strong{data frame} with 1 numeric column.
\item A \strong{matrix} with 1 numeric column.
\item A numeric \strong{vector}.
}}

\item{epochs}{An integer for the number of epochs of training.}

\item{penalty}{The amount of weight decay (i.e., L2 regularization).}

\item{validation}{The proportion of the data randomly assigned to a
validation set.}

\item{optimizer}{The method used in the optimization procedure. Possible choices
are 'LBFGS' and 'SGD'. Default is 'LBFGS'.}

\item{learn_rate}{A positive number. Default is 1 for LBFGS; smaller values
are normally chosen for other optimizers. (\code{optimizer = "SGD"} only)}

\item{momentum}{A positive number on \verb{[0, 1]} for the momentum parameter in
gradient descent. (\code{optimizer = "SGD"} only)}

\item{batch_size}{An integer for the number of training set points in each
batch.}

\item{class_weights}{Numeric class weights (classification only). The value
can be:
\itemize{
\item A named numeric vector (in any order) where the names are the outcome
factor levels.
\item An unnamed numeric vector assumed to be in the same order as the outcome
factor levels.
\item A single numeric value for the least frequent class in the training data
and all other classes receive a weight of one.
}}

\item{stop_iter}{A non-negative integer for how many iterations with no
improvement before stopping.}

\item{verbose}{A logical that prints out the iteration history.}

\item{formula}{A formula specifying the outcome terms on the left-hand side,
and the predictor terms on the right-hand side.}

\item{data}{When a \strong{recipe} or \strong{formula} is used, \code{data} is specified as:
\itemize{
\item A \strong{data frame} containing both the predictors and the outcome.
}}
}
\value{
A \code{lantern_logistic_reg} object with elements:
\itemize{
\item \code{models_obj}: a serialized raw vector for the torch module.
\item \code{estimates}: a list of matrices with the model parameter estimates per
epoch.
\item \code{best_epoch}: an integer for the epoch with the smallest loss.
\item \code{loss}: A vector of loss values (MSE for regression, negative log-
likelihood for classification) at each epoch.
\item \code{dim}: A list of data dimensions.
\item \code{parameters}: A list of some tuning parameter values.
\item \code{blueprint}: The \code{hardhat} blueprint data.
}
}
\description{
\code{lantern_logistic_reg()} fits a model.
}
\details{
Despite its name, this function can be used with three or more classes (e.g.,
multinomial regression).

The \emph{predictors} data should all be numeric and encoded in the same units (e.g.
standardized to the same range or distribution). If there are factor
predictors, use a recipe or formula to create indicator variables (or some
other method) to make them numeric.
}
\examples{
if (torch::torch_is_installed()) {

 ## -----------------------------------------------------------------------------
 # increase # epochs to get better results

 data(cells, package = "modeldata")

 cells$case <- NULL

 set.seed(122)
 in_train <- sample(1:nrow(cells), 1000)
 cells_train <- cells[ in_train,]
 cells_test  <- cells[-in_train,]

 # Using matrices
 set.seed(1)
 lantern_logistic_reg(x = as.matrix(cells_train[, c("fiber_width_ch_1", "width_ch_1")]),
                      y = cells_train$class,
                      penalty = 0.10, epochs = 3)

 # Using recipe
 library(recipes)

 cells_rec <-
  recipe(class ~ ., data = cells_train) \%>\%
  # Transform some highly skewed predictors
  step_YeoJohnson(all_predictors()) \%>\%
  step_normalize(all_predictors()) \%>\%
  step_pca(all_predictors(), num_comp = 10)

 set.seed(2)
 fit <- lantern_logistic_reg(cells_rec, data = cells_train,
                             penalty = .01, epochs = 5)
 fit

 autoplot(fit)

 library(yardstick)
 predict(fit, cells_test, type = "prob") \%>\%
  bind_cols(cells_test) \%>\%
  roc_auc(class, .pred_PS)

 # ------------------------------------------------------------------------------
 # multinomial regression

 data(penguins, package = "modeldata")

 penguins <- penguins \%>\% na.omit()

 set.seed(122)
 in_train <- sample(1:nrow(penguins), 200)
 penguins_train <- penguins[ in_train,]
 penguins_test  <- penguins[-in_train,]

 rec <- recipe(island ~ ., data = penguins_train) \%>\%
  step_dummy(species, sex) \%>\%
  step_normalize(all_predictors())

 set.seed(3)
 fit <- lantern_logistic_reg(rec, data = penguins_train, epochs = 5)
 fit

 predict(fit, penguins_test) \%>\%
  bind_cols(penguins_test) \%>\%
  conf_mat(island, .pred_class)
}

}
